{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data-Science\\Gen_AI\\LLM\\Langchain\\Document-based-Q-and-A\\docQnA\\lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "#from langchain_community.document_loaders import PyPDFLoader\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import FAISS\n",
    "import streamlit as st\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "#embeddings = HuggingFaceInstructEmbeddings(model_name=\"WhereIsAI/UAE-Large-V1\")\n",
    "embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",model_kwargs={\"device\":\"cpu\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Data-Science\\Gen_AI\\LLM\\Langchain\\Document-based-Q-and-A\\docQnA\n"
     ]
    }
   ],
   "source": [
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "llm=CTransformers(\n",
    "        #model='D:\\Data-Science\\Gen_AI\\LLM\\Langchain\\email-generator\\models\\llama-2-7b-chat.ggmlv3.q8_0.bin',\n",
    "        model='TheBloke/Llama-2-7B-Chat-GGUF',\n",
    "        #model='syedzaidi-kiwi/Llama-2-7b-chat-finetune',\n",
    "        model_type='llama',\n",
    "        config={'max_new_tokens':256,\n",
    "                'temperature':0}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_loader():\n",
    "    loader=DirectoryLoader(f'{folder_path}\\\\Data',glob=\"./*.pdf\",loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents():\n",
    "    documents=document_loader()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    texts=text_splitter.split_documents(documents)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f\"{folder_path}\\\\faiss_index_docQnA\"):\n",
    "    print(\"Vector Store exists\")\n",
    "    VectorStore=FAISS.load_local(f\"{folder_path}\\\\faiss_index_docQnA\",embeddings,allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    print(\"Vector Store does not exists. Creating first time hence will take few minutes\")\n",
    "    os.makedirs(f\"{folder_path}\\\\faiss_index_docQnA\")\n",
    "    print(f\"The Vector store creation is in progress ....\")\n",
    "    texts=split_documents()\n",
    "    VectorStore=FAISS.from_documents(texts,embeddings)\n",
    "    print(f\"The Vector store creation is done ....\")\n",
    "    VectorStore.save_local(f\"{folder_path}\\\\faiss_index_docQnA\")\n",
    "    print(f\"Vector DB is saving to local drive at {folder_path}\\\\faiss_index_docQnA Finished!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1e841571a30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver=VectorStore.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Ishu Srivastava  \\nPMP Certified Professional  \\n \\nDynamic and results -driv en professional with a focus on technical project \\nmanagement and data science. Seeking opportunities in Noida or Delhi/NCR \\nregion to leverage expertise in project management practices and hands -on \\ntechnical skills.  \\n  \\n \\nE-MAIL   ishu.cs@gmail.com                                      \\nMOBILE    +91 -9953697986  \\nLINKEDIN: www.linkedin.com/in/ishu -\\nsrivastava/  \\nGITHUB: https://github.com/ishu -cs', metadata={'source': 'D:\\\\Data-Science\\\\Gen_AI\\\\LLM\\\\Langchain\\\\Document-based-Q-and-A\\\\docQnA\\\\Data\\\\Ishu_Srivastava.pdf', 'page': 0}),\n",
       " Document(page_content='➢ Played a pivotal role in ensuring regulatory compliance and data integrity by implementing rigorous data governance policies \\nand procedures.  \\n➢ Collaborated closely with stakeholders to define and prioritize database requirements, aligning technical solutions with busi ness \\nobjectives and goals.  \\n \\n PREVIOUS W ORK EXPERIENCE  \\n \\nNov’13 -Jan’16 : Genpact, Noida as Principal Consultant  \\n \\nNov’12 -Nov’13: IBM India Private Limited, Noida as Database Administrator', metadata={'source': 'D:\\\\Data-Science\\\\Gen_AI\\\\LLM\\\\Langchain\\\\Document-based-Q-and-A\\\\docQnA\\\\Data\\\\Ishu_Srivastava.pdf', 'page': 1}),\n",
       " Document(page_content='PROFILE SUMMARY  \\n➢ Offering expertise  of over 14  years  with consistent track record of progression , repeatedly achieving goals and \\nproducing immediate improvements:  \\no 3 Years in Data Science & Analytics  \\no 11 Years in Banking IT -Infrastructure  \\n➢ Developed process wal kthroughs, identified use cases &  planned and executed short  and long -term strategies for the', metadata={'source': 'D:\\\\Data-Science\\\\Gen_AI\\\\LLM\\\\Langchain\\\\Document-based-Q-and-A\\\\docQnA\\\\Data\\\\Ishu_Srivastava.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver.get_relevant_documents(\"What is the experience summary of Ishu?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_chain(VectorStore):\n",
    "    retriver=VectorStore.as_retriever(search_kwargs={\"k\":3})\n",
    "    qa_chain=RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\",retriever=retriver.get_relevant_documents,input_key=\"question\")\n",
    "    return qa_chain,retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input_and_execute_function():\n",
    "    # Get input from the user\n",
    "    user_input = input(\"Please enter something (type 'stop' to quit): \")\n",
    "    \n",
    "    # Check if user wants to stop\n",
    "    if user_input.lower() == 'stop':\n",
    "        print(\"Stopping program...\")\n",
    "        return False\n",
    "    \n",
    "    # Call the function with the user input as parameter\n",
    "    my_function(user_input)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "ref_doc = []\n",
    "page =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path,embeddings):\n",
    "  VectorStore=FAISS.load_local(f\"{path}\\\\faiss_index_docQnA\",embeddings,allow_dangerous_deserialization=True)\n",
    "  return VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_instructEmbedd = load_embeddings(path=f'{folder_path}',embeddings=embeddings)#,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db_instructEmbedd.as_retriever(search_kwargs={\"k\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_instrucEmbed = RetrievalQA.from_chain_type(llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    input_key=\"question\"\n",
    "    #return_source_document = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for RetrievalQA\nretriever\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m qa_chain\u001b[38;5;241m=\u001b[39m\u001b[43mRetrievalQA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_chain_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchain_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstuff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minput_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data-Science\\Gen_AI\\LLM\\Langchain\\Document-based-Q-and-A\\docQnA\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:108\u001b[0m, in \u001b[0;36mBaseRetrievalQA.from_chain_type\u001b[1;34m(cls, llm, chain_type, chain_type_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m _chain_type_kwargs \u001b[38;5;241m=\u001b[39m chain_type_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    105\u001b[0m combine_documents_chain \u001b[38;5;241m=\u001b[39m load_qa_chain(\n\u001b[0;32m    106\u001b[0m     llm, chain_type\u001b[38;5;241m=\u001b[39mchain_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_chain_type_kwargs\n\u001b[0;32m    107\u001b[0m )\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(combine_documents_chain\u001b[38;5;241m=\u001b[39mcombine_documents_chain, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Data-Science\\Gen_AI\\LLM\\Langchain\\Document-based-Q-and-A\\docQnA\\lib\\site-packages\\langchain_core\\load\\serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32md:\\Data-Science\\Gen_AI\\LLM\\Langchain\\Document-based-Q-and-A\\docQnA\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for RetrievalQA\nretriever\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "qa_chain=RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\",input_key=\"question\",retriever=retriver.get_relevant_documents(\"question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data-Science\\Gen_AI\\LLM\\Langchain\\Document-based-Q-and-A\\docQnA\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "answer = qa_chain_instrucEmbed(\"What is the experience summary of Ishu?\")\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the experience summary of Ishu?', 'result': ' Based on the provided information, I can see that Ishu has 10 years of experience in project management and data science. He is PMP certified and has worked in various industries including IT, Finance, and Manufacturing. He has also worked as a freelancer and has experience in leading teams and managing projects remotely.\\n\\nPlease answer the question based on the provided information.'}\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(user_input):\n",
    "    questions.append(user_input)\n",
    "    ans = qa_chain_instrucEmbed(user_input)\n",
    "    answers.append(ans.get('result'))\n",
    "    ref_doc.append(retriever.get_relevant_documents(user_input)[0].metadata.get('source'))\n",
    "    page.append(retriever.get_relevant_documents(user_input)[0].metadata.get('page'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docQnA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
